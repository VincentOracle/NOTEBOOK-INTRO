{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b81a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assignment 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ef8c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grader area\n",
    "import numpy as np\n",
    "G=np.zeros[10,10]\n",
    "maxScore=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9c35ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Ipython.display import Math \n",
    "from Ipython.display import Latex\n",
    "import numpy as np\n",
    "import os\n",
    "import struct\n",
    "from sklearn.metrix import classification_report,confusion_matrix\n",
    "from sklearn.neural_network MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cabfa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question 0: MLP with scikit-learn: Explore the out put of the MNIST dataset. \n",
    "The purpose of this question is to get to practice with MLP classifiers .We will be using the MNIST dataset\n",
    "Let's firs load the MNIST dataset\n",
    "from sklearn.datasets import fetch_openn1\n",
    "from sklearn.model_selection import train_test_split\n",
    "x,y=fetch_openn1('MNIST_784',version=1,return_x_y=true)\n",
    "y=y.astype(int)\n",
    "x=((x/255.)-.5)*2\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=10000,random_state=123,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e8923c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q0-0: Find a setting for a batch_size and max_iter so that the subsequent fit function converges \n",
    "\n",
    "mlp_mnist= MLPClassifier(verbose=true,hidden_layer_sizes=(50,),batch_size=5,1\\\n",
    "                        max_iter=50,solver='sgd',activation='logistic',\\\n",
    "                        learning_rate='constant',learning_rate_init=0.001,random_state=1)\n",
    "\n",
    "mlp_mnist.fit(x_tarin,y_train)\n",
    "predictions=mlp_mnist.predict(x_test)\n",
    "probability_predictions=mlp_mnist.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347fd28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q0-Write a short function that outputs the second best prediction for each point-that is,label that gets the highest probability in \n",
    "#the softmax output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcbce770",
   "metadata": {},
   "outputs": [],
   "source": [
    "For each data point misclasified by the model,determine whether the second best prediction is actually the correct label.Calculate the \n",
    "percentage of those misclassified points that are correctly classified based on the second best prediction. \n",
    "Write you code and comments\n",
    "Q0-3 From a human point of view,can we perhaps see a frequency similarity between handwritten digits 3 and 5(sometimes we have to pay closer attention to figure out what the true written digits is). We may want to ask if the MLP also detects digit similarities. \n",
    "\n",
    "Consider then Xi of data points taht label i(e.g, all data points with label 5).For each label j not equal to i,report the frequency by which labelj(e.g label 3) shows up as the second best prediction for points in Xi.\n",
    "Further Clarification: Suppose we have 100 datapoints with labeli=5 is 28%.We want to compute that frequency for every i and j.\n",
    "Give your code and comment on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3eaeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 1: Working with Wram start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f3417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1-0. MLP classifiers in scikit-learn have an option for so called 'warm start'.Do a research and fid out what it is.Then:\n",
    "#Give an example of warm start.Specifically train the network for k epochs, and then using warm start continue the training for another k\n",
    "#epochs.Here k is a parameter of your choice.\n",
    "#Write your code and comments about your findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ee50259",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1-1. Randomly divide the MNIST dataset into three parts train(50000),train2(10000),test(10000).Make sure the that all number classes are presnt in both train1 and train2 \n",
    "#Write your code and comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664a41a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1-2 Use warm start and train your model using the train 1 dataset for 2k epochs. Then, using warm start,continue the training with the train2\n",
    "the dataset for another 2k epochs\n",
    "Here, k is the same parameter that you used above.Notice that each point is considered 2k times in the training, exactly as in  part 0.\n",
    "Write your code and comments\n",
    "\n",
    "Which of the two above strategies works better(Q1-0 or Q1-2)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b160dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2-0.Create a new dataset X1, where each row is the same as the corresponding row of X, except in the first column, which contains the label of the corresponding image by 255.Then split the X1 into traing set and test set,as we did with X1.\n",
    "#Q2-1.With label of the image planted in the image itself,a neural network can be achieved with accuracy of 100%.This is because all the weights connecting pixels 2...28 squared can be set to 0, and so effectively the only feature that will be taken into account is the first pixel.The question is whether an MLP can indeed discover this weighting via training? \n",
    "#Use an MLP classifier with one hidden layer of any size you want.Train it on X and report the accuracy.\n",
    "#Does it reach 100%? Is the accuracy better relative to training with the original input X?\n",
    "#Write your code and explanation "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
